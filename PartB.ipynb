{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb03264-3773-4113-b7cf-100a5b08d681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/user/Documents/wandb/run-20250419_133934-206a54mj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ce24d903-indian-institute-of-technology-madras/iNaturalist_EffNetV2S_finetune_2/runs/206a54mj' target=\"_blank\">sparkling-wood-2</a></strong> to <a href='https://wandb.ai/ce24d903-indian-institute-of-technology-madras/iNaturalist_EffNetV2S_finetune_2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ce24d903-indian-institute-of-technology-madras/iNaturalist_EffNetV2S_finetune_2' target=\"_blank\">https://wandb.ai/ce24d903-indian-institute-of-technology-madras/iNaturalist_EffNetV2S_finetune_2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ce24d903-indian-institute-of-technology-madras/iNaturalist_EffNetV2S_finetune_2/runs/206a54mj' target=\"_blank\">https://wandb.ai/ce24d903-indian-institute-of-technology-madras/iNaturalist_EffNetV2S_finetune_2/runs/206a54mj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Stage 1: Training classifier only\n",
      "stage1 → TrainLoss: 1.2273 TrainAcc: 0.6309 | ValLoss: 0.7512 ValAcc: 0.7835\n",
      "stage1 → TrainLoss: 0.9858 TrainAcc: 0.6855 | ValLoss: 0.7049 ValAcc: 0.7845\n",
      "stage1 → TrainLoss: 0.9567 TrainAcc: 0.6929 | ValLoss: 0.6758 ValAcc: 0.7980\n",
      "stage1 → TrainLoss: 0.9553 TrainAcc: 0.6930 | ValLoss: 0.6618 ValAcc: 0.7885\n",
      "stage1 → TrainLoss: 0.9473 TrainAcc: 0.6971 | ValLoss: 0.6557 ValAcc: 0.7930\n",
      "stage1 → TrainLoss: 0.9339 TrainAcc: 0.6982 | ValLoss: 0.6637 ValAcc: 0.7985\n",
      "stage1 → TrainLoss: 0.9406 TrainAcc: 0.6979 | ValLoss: 0.6386 ValAcc: 0.8015\n",
      "stage1 → TrainLoss: 0.9230 TrainAcc: 0.7051 | ValLoss: 0.6273 ValAcc: 0.8045\n",
      "stage1 → TrainLoss: 0.9405 TrainAcc: 0.7000 | ValLoss: 0.6436 ValAcc: 0.8050\n",
      "stage1 → TrainLoss: 0.9303 TrainAcc: 0.7047 | ValLoss: 0.6237 ValAcc: 0.8045\n",
      "stage1 → TrainLoss: 0.9409 TrainAcc: 0.7008 | ValLoss: 0.6314 ValAcc: 0.8035\n",
      "stage1 → TrainLoss: 0.9297 TrainAcc: 0.7011 | ValLoss: 0.6321 ValAcc: 0.8070\n",
      "stage1 → TrainLoss: 0.9197 TrainAcc: 0.7066 | ValLoss: 0.6186 ValAcc: 0.8145\n",
      "stage1 → TrainLoss: 0.9273 TrainAcc: 0.7010 | ValLoss: 0.6028 ValAcc: 0.8140\n",
      "stage1 → TrainLoss: 0.9172 TrainAcc: 0.7069 | ValLoss: 0.6083 ValAcc: 0.8195\n",
      "stage1 → TrainLoss: 0.9259 TrainAcc: 0.7058 | ValLoss: 0.6146 ValAcc: 0.8150\n",
      "stage1 → TrainLoss: 0.9251 TrainAcc: 0.7021 | ValLoss: 0.6198 ValAcc: 0.8135\n",
      "stage1 → TrainLoss: 0.9143 TrainAcc: 0.7104 | ValLoss: 0.6089 ValAcc: 0.8115\n",
      "stage1 → TrainLoss: 0.9265 TrainAcc: 0.7025 | ValLoss: 0.6259 ValAcc: 0.8125\n",
      "stage1 → TrainLoss: 0.9308 TrainAcc: 0.7027 | ValLoss: 0.6297 ValAcc: 0.8025\n",
      "stage1 → TrainLoss: 0.9186 TrainAcc: 0.7048 | ValLoss: 0.6051 ValAcc: 0.8250\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import wandb\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "def train():\n",
    "    # 1) Initialize wandb\n",
    "    wandb.init(project=\"iNaturalist_EffNetV2S_finetune_2\", config={\n",
    "        \"architecture\": \"EfficientNetV2-S\",\n",
    "        \"dataset\": \"iNaturalist12K\",\n",
    "        \"num_classes\": 10,\n",
    "        \"batch_size\": 32,\n",
    "        \"epochs_stage1\": 30,\n",
    "        \"epochs_stage2\": 30,\n",
    "        \"epochs_stage3\": 50,\n",
    "        \"lr_stage1\": 1e-3,\n",
    "        \"lr_stage2\": 1e-4,\n",
    "        \"lr_stage3\": 1e-5,\n",
    "        \"img_size\": 224,\n",
    "    })\n",
    "    config = wandb.config\n",
    "\n",
    "    # 2) Device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # 3) Data augmentation and normalization\n",
    "    data_transforms = {\n",
    "        \"train\": transforms.Compose([\n",
    "            transforms.RandomResizedCrop(config.img_size),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomAffine(degrees=15, translate=(0.1,0.1), scale=(0.9,1.1)),\n",
    "            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
    "        ]),\n",
    "        \"val\": transforms.Compose([\n",
    "            transforms.Resize(int(config.img_size*1.15)),\n",
    "            transforms.CenterCrop(config.img_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
    "        ]),\n",
    "    }\n",
    "\n",
    "    # 4) Datasets & Loaders (update these paths)\n",
    "    train_dir = \"/home/user/kartikey_phd/DA6401/nature_12K/inaturalist_12K/train\"\n",
    "    val_dir   = \"/home/user/kartikey_phd/DA6401/nature_12K/inaturalist_12K/val\"\n",
    "    image_datasets = {\n",
    "        x: datasets.ImageFolder(train_dir if x==\"train\" else val_dir,\n",
    "                                 data_transforms[x])\n",
    "        for x in [\"train\",\"val\"]\n",
    "    }\n",
    "    dataloaders = {\n",
    "        x: DataLoader(image_datasets[x],\n",
    "                      batch_size=config.batch_size,\n",
    "                      shuffle=(x==\"train\"),\n",
    "                      num_workers=4)\n",
    "        for x in [\"train\",\"val\"]\n",
    "    }\n",
    "\n",
    "    # 5) Load EfficientNetV2-S pretrained on ImageNet\n",
    "    model = models.efficientnet_v2_s(\n",
    "        weights=models.EfficientNet_V2_S_Weights.IMAGENET1K_V1\n",
    "    )\n",
    "    # Replace classifier head\n",
    "    in_features = model.classifier[1].in_features\n",
    "    model.classifier[1] = nn.Linear(in_features, config.num_classes)\n",
    "\n",
    "    model = model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    def run_epoch(stage):\n",
    "        \"\"\" helper to run one epoch of train+val and log metrics \"\"\"\n",
    "        model.train()\n",
    "        running_loss, running_corrects = 0.0, 0\n",
    "        for inputs, labels in dataloaders[\"train\"]:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += (outputs.argmax(1) == labels).sum().item()\n",
    "        epoch_loss = running_loss / len(image_datasets[\"train\"])\n",
    "        epoch_acc  = running_corrects / len(image_datasets[\"train\"])\n",
    "\n",
    "        model.eval()\n",
    "        val_loss, val_corrects = 0.0, 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in dataloaders[\"val\"]:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                val_corrects += (outputs.argmax(1) == labels).sum().item()\n",
    "        val_loss /= len(image_datasets[\"val\"])\n",
    "        val_acc  = val_corrects / len(image_datasets[\"val\"])\n",
    "\n",
    "        wandb.log({\n",
    "            f\"{stage}_train_loss\": epoch_loss,\n",
    "            f\"{stage}_train_acc\": epoch_acc,\n",
    "            f\"{stage}_val_loss\": val_loss,\n",
    "            f\"{stage}_val_acc\": val_acc,\n",
    "        })\n",
    "        print(f\"{stage} → TrainLoss: {epoch_loss:.4f} TrainAcc: {epoch_acc:.4f} | \"\n",
    "              f\"ValLoss: {val_loss:.4f} ValAcc: {val_acc:.4f}\")\n",
    "\n",
    "    # ─────────────────────────────────────────────────────────────\n",
    "    # Stage 1: Freeze all but classifier\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    for param in model.classifier.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "    optimizer = optim.Adam(model.classifier.parameters(), lr=config.lr_stage1)\n",
    "    print(\">>> Stage 1: Training classifier only\")\n",
    "    for epoch in range(config.epochs_stage1):\n",
    "        run_epoch(\"stage1\")\n",
    "\n",
    "    # ─────────────────────────────────────────────────────────────\n",
    "    # Stage 2: Unfreeze last feature block + classifier\n",
    "    # EfficientNetV2-S features are in model.features (a Sequential). Unfreeze last block.\n",
    "    for param in model.features[-1].parameters():\n",
    "        param.requires_grad = True\n",
    "    optimizer = optim.Adam(\n",
    "        filter(lambda p: p.requires_grad, model.parameters()),\n",
    "        lr=config.lr_stage2\n",
    "    )\n",
    "    print(\"\\n>>> Stage 2: Unfreezing last block + classifier\")\n",
    "    for epoch in range(config.epochs_stage2):\n",
    "        run_epoch(\"stage2\")\n",
    "\n",
    "    # ─────────────────────────────────────────────────────────────\n",
    "    # Stage 3: Unfreeze everything\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = True\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config.lr_stage3)\n",
    "    print(\"\\n>>> Stage 3: Fine‑tuning entire network\")\n",
    "    for epoch in range(config.epochs_stage3):\n",
    "        run_epoch(\"stage3\")\n",
    "\n",
    "    wandb.finish()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9012fd13-df96-4ff7-8758-a041e83edb33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
